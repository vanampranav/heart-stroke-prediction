{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e978ebc6-ee6a-45ba-8413-bcfadb2ac0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 02:44:17.990151: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-09 02:44:17.994090: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-09 02:44:18.007712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736370858.030584   25168 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736370858.037396   25168 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-09 02:44:18.059742: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/vanamabhinav/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-01-09 02:44:20.304776: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1, Best Accuracy: 0.7666666507720947\n",
      "Generation 2, Best Accuracy: 0.75\n",
      "Generation 3, Best Accuracy: 0.800000011920929\n",
      "Generation 4, Best Accuracy: 0.75\n",
      "Generation 5, Best Accuracy: 0.7666666507720947\n",
      "Best Individual: [30, 0.5, 15, 0.4389933370184338, 0.01, 85]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81        35\n",
      "           1       0.81      0.52      0.63        25\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.77      0.72      0.72        60\n",
      "weighted avg       0.76      0.75      0.74        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import random\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Standardize dataset\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Particle Swarm Optimization (PSO) parameters\n",
    "SWARM_SIZE = 10\n",
    "GENERATIONS = 5\n",
    "W = 0.5  # Inertia weight\n",
    "C1 = 1.5  # Cognitive (personal) weight\n",
    "C2 = 1.5  # Social (group) weight\n",
    "\n",
    "def evaluate_model(individual):\n",
    "    \"\"\"Evaluate a model based on an individual's parameters.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(individual[0], input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(individual[1]),\n",
    "        Dense(individual[2], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(individual[3]),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=individual[4]), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=individual[5], verbose=0, validation_split=0.2)\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def initialize_particles():\n",
    "    \"\"\"Generate an initial swarm of particles.\"\"\"\n",
    "    particles = [\n",
    "        [random.randint(10, 100),  # First layer neurons\n",
    "         random.uniform(0.1, 0.5),  # First layer dropout\n",
    "         random.randint(10, 100),  # Second layer neurons\n",
    "         random.uniform(0.1, 0.5),  # Second layer dropout\n",
    "         random.uniform(0.0001, 0.01),  # Learning rate\n",
    "         random.randint(16, 128)]  # Batch size\n",
    "        for _ in range(SWARM_SIZE)\n",
    "    ]\n",
    "    velocities = [\n",
    "        [random.uniform(-1, 1) for _ in range(len(particles[0]))]\n",
    "        for _ in range(SWARM_SIZE)\n",
    "    ]\n",
    "    return particles, velocities\n",
    "\n",
    "# PSO optimization\n",
    "particles, velocities = initialize_particles()\n",
    "personal_best = particles.copy()\n",
    "global_best = max(particles, key=evaluate_model)\n",
    "personal_best_scores = [evaluate_model(p) for p in particles]\n",
    "\n",
    "def update_velocity(velocity, particle, personal_best, global_best):\n",
    "    \"\"\"Update the velocity of a particle.\"\"\"\n",
    "    new_velocity = []\n",
    "    for i in range(len(particle)):\n",
    "        r1, r2 = random.random(), random.random()\n",
    "        cognitive = C1 * r1 * (personal_best[i] - particle[i])\n",
    "        social = C2 * r2 * (global_best[i] - particle[i])\n",
    "        new_velocity.append(W * velocity[i] + cognitive + social)\n",
    "    return new_velocity\n",
    "\n",
    "def update_particle(particle, velocity):\n",
    "    \"\"\"Update the position of a particle.\"\"\"\n",
    "    new_particle = [\n",
    "        max(10, min(100, int(particle[0] + velocity[0]))),\n",
    "        max(0.1, min(0.5, particle[1] + velocity[1])),\n",
    "        max(10, min(100, int(particle[2] + velocity[2]))),\n",
    "        max(0.1, min(0.5, particle[3] + velocity[3])),\n",
    "        max(0.0001, min(0.01, particle[4] + velocity[4])),\n",
    "        max(16, min(128, int(particle[5] + velocity[5])))\n",
    "    ]\n",
    "    return new_particle\n",
    "\n",
    "for generation in range(GENERATIONS):\n",
    "    for i in range(SWARM_SIZE):\n",
    "        fitness = evaluate_model(particles[i])\n",
    "        if fitness > personal_best_scores[i]:\n",
    "            personal_best_scores[i] = fitness\n",
    "            personal_best[i] = particles[i]\n",
    "        if fitness > evaluate_model(global_best):\n",
    "            global_best = particles[i]\n",
    "        velocities[i] = update_velocity(velocities[i], particles[i], personal_best[i], global_best)\n",
    "        particles[i] = update_particle(particles[i], velocities[i])\n",
    "\n",
    "    print(f\"Generation {generation + 1}, Best Accuracy: {evaluate_model(global_best)}\")\n",
    "\n",
    "# Best solution\n",
    "best_individual = global_best\n",
    "print(\"Best Individual:\", best_individual)\n",
    "\n",
    "# Train the best model\n",
    "best_model = Sequential([\n",
    "    Dense(best_individual[0], input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(best_individual[1]),\n",
    "    Dense(best_individual[2], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(best_individual[3]),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_individual[4]), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "best_model.fit(X_train, y_train, epochs=20, batch_size=best_individual[5], verbose=0)\n",
    "\n",
    "# Extract features for Random Forest\n",
    "train_features = best_model.predict(X_train)\n",
    "test_features = best_model.predict(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(train_features, y_train)\n",
    "\n",
    "# Predictions and classification report\n",
    "rf_predictions = rf_model.predict(test_features)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0796692-2614-4205-90f0-1c6466de8c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96694547-2edc-4d94-b502-19993ec2248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7121eb-8776-4d91-9046-97c758437cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 02:12:58.059696: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-07 02:12:58.063093: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-07 02:12:58.075840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736196178.094819  609339 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736196178.099569  609339 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-07 02:12:58.115127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-07 02:13:00.375050: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(input_dim,)),  # Specify the input shape here\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a0fb05-16c5-4ef6-80bd-bae43fb33dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 11  # Number of features in your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07cd1ac-9002-4734-ab81-4c2d370b7236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "x=10\n",
    "y=10\n",
    "z=x+y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e04ee5-a046-4596-abc5-70e91305c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanamabhinav/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1, Best Accuracy: 0.8166666626930237\n",
      "Generation 2, Best Accuracy: 0.8166666626930237\n",
      "Generation 3, Best Accuracy: 0.8166666626930237\n",
      "Generation 4, Best Accuracy: 0.8166666626930237\n",
      "Generation 5, Best Accuracy: 0.8166666626930237\n",
      "Generation 6, Best Accuracy: 0.8166666626930237\n",
      "Generation 7, Best Accuracy: 0.8166666626930237\n",
      "Generation 8, Best Accuracy: 0.8166666626930237\n",
      "Generation 9, Best Accuracy: 0.8166666626930237\n",
      "Generation 10, Best Accuracy: 0.8166666626930237\n",
      "Best Individual: [69, 0.25887004795805824, 78, 0.27533479254857013, 0.0024852601360624274, 93]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.81        35\n",
      "           1       0.86      0.48      0.62        25\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.79      0.71      0.72        60\n",
      "weighted avg       0.78      0.75      0.73        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import random\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Standardize dataset\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Genetic Algorithm Parameters\n",
    "POPULATION_SIZE = 20\n",
    "GENERATIONS = 10\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "def evaluate_model(individual):\n",
    "    \"\"\"Evaluate a model based on an individual's parameters.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(individual[0], input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(individual[1]),\n",
    "        Dense(individual[2], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(individual[3]),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=individual[4]), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=individual[5], verbose=0, validation_split=0.2)\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def initialize_population():\n",
    "    \"\"\"Initialize the population with random individuals.\"\"\"\n",
    "    population = [\n",
    "        [random.randint(10, 100),  # First layer neurons\n",
    "         random.uniform(0.1, 0.5),  # First layer dropout\n",
    "         random.randint(10, 100),  # Second layer neurons\n",
    "         random.uniform(0.1, 0.5),  # Second layer dropout\n",
    "         random.uniform(0.0001, 0.01),  # Learning rate\n",
    "         random.randint(16, 128)]  # Batch size\n",
    "        for _ in range(POPULATION_SIZE)\n",
    "    ]\n",
    "    return population\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    \"\"\"Perform crossover between two parents.\"\"\"\n",
    "    point = random.randint(1, len(parent1) - 2)  # Random crossover point\n",
    "    child1 = parent1[:point] + parent2[point:]\n",
    "    child2 = parent2[:point] + parent1[point:]\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(individual):\n",
    "    \"\"\"Perform mutation on an individual.\"\"\"\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        index = random.randint(0, len(individual) - 1)\n",
    "        if index in [0, 2, 5]:  # Integer values\n",
    "            individual[index] = random.randint(10, 100 if index != 5 else 128)\n",
    "        elif index in [1, 3]:  # Float values for dropout\n",
    "            individual[index] = random.uniform(0.1, 0.5)\n",
    "        elif index == 4:  # Float values for learning rate\n",
    "            individual[index] = random.uniform(0.0001, 0.01)\n",
    "    return individual\n",
    "\n",
    "# Initialize population\n",
    "population = initialize_population()\n",
    "best_individual = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for generation in range(GENERATIONS):\n",
    "    # Evaluate fitness\n",
    "    fitness_scores = [evaluate_model(individual) for individual in population]\n",
    "    \n",
    "    # Update the best individual\n",
    "    for i, score in enumerate(fitness_scores):\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_individual = population[i]\n",
    "    \n",
    "    # Select parents based on fitness (tournament selection)\n",
    "    selected_parents = []\n",
    "    for _ in range(POPULATION_SIZE // 2):\n",
    "        parent1, parent2 = random.choices(population, weights=fitness_scores, k=2)\n",
    "        selected_parents.append((parent1, parent2))\n",
    "    \n",
    "    # Generate next population through crossover and mutation\n",
    "    next_population = []\n",
    "    for parent1, parent2 in selected_parents:\n",
    "        child1, child2 = crossover(parent1, parent2)\n",
    "        next_population.extend([mutate(child1), mutate(child2)])\n",
    "    \n",
    "    population = next_population[:POPULATION_SIZE]  # Ensure population size remains constant\n",
    "    print(f\"Generation {generation + 1}, Best Accuracy: {best_score}\")\n",
    "\n",
    "# Best solution\n",
    "print(\"Best Individual:\", best_individual)\n",
    "\n",
    "# Train the best model\n",
    "best_model = Sequential([\n",
    "    Dense(best_individual[0], input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(best_individual[1]),\n",
    "    Dense(best_individual[2], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(best_individual[3]),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_individual[4]), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "best_model.fit(X_train, y_train, epochs=20, batch_size=best_individual[5], verbose=0)\n",
    "\n",
    "# Extract features for Random Forest\n",
    "train_features = best_model.predict(X_train)\n",
    "test_features = best_model.predict(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(train_features, y_train)\n",
    "\n",
    "# Predictions and classification report\n",
    "rf_predictions = rf_model.predict(test_features)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c66c087-ee83-4804-ae1e-1fc95cd801eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m         fitness \u001b[38;5;241m=\u001b[39m evaluate_model(particles[i])\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fitness \u001b[38;5;241m>\u001b[39m personal_best_scores[i]:\n\u001b[1;32m     10\u001b[0m             personal_best_scores[i] \u001b[38;5;241m=\u001b[39m fitness\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to store global best accuracy per generation\n",
    "global_best_accuracies = []\n",
    "\n",
    "for generation in range(10):\n",
    "    for i in range(10):\n",
    "        fitness = evaluate_model(particles[i])\n",
    "        if fitness > personal_best_scores[i]:\n",
    "            personal_best_scores[i] = fitness\n",
    "            personal_best[i] = particles[i]\n",
    "        if fitness > evaluate_model(global_best):\n",
    "            global_best = particles[i]\n",
    "        velocities[i] = update_velocity(velocities[i], particles[i], personal_best[i], global_best)\n",
    "        particles[i] = update_particle(particles[i], velocities[i])\n",
    "\n",
    "    # Track the global best accuracy for the current generation\n",
    "    best_accuracy = evaluate_model(global_best)\n",
    "    global_best_accuracies.append(best_accuracy)\n",
    "    print(f\"Generation {generation + 1}, Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "# Plot the global best accuracy over generations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, GENERATIONS + 1), global_best_accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title(\"Global Best Accuracy Over Generations\", fontsize=16)\n",
    "plt.xlabel(\"Generation\", fontsize=14)\n",
    "plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a9efe1-e5b6-4fac-a5ba-d85bee04991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:31:19.032540: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-29 10:31:19.186715: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-29 10:31:19.458542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738126879.702434    6186 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738126879.765191    6186 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 10:31:20.459039: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/vanamabhinav/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-01-29 10:31:24.574406: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1, Best Accuracy: 0.800000011920929\n",
      "Generation 2, Best Accuracy: 0.800000011920929\n",
      "Generation 3, Best Accuracy: 0.8166666626930237\n",
      "Generation 4, Best Accuracy: 0.8166666626930237\n",
      "Generation 5, Best Accuracy: 0.8166666626930237\n",
      "Generation 6, Best Accuracy: 0.8166666626930237\n",
      "Generation 7, Best Accuracy: 0.8166666626930237\n",
      "Generation 8, Best Accuracy: 0.8166666626930237\n",
      "Generation 9, Best Accuracy: 0.8166666626930237\n",
      "Generation 10, Best Accuracy: 0.8166666626930237\n",
      "Best Individual: [92, 0.28831034030097713, 38, 0.194902292213839, 0.0032690074324506838, 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Stroke Model Saved!\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Random Forest Model Saved!\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81        35\n",
      "           1       0.81      0.52      0.63        25\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.77      0.72      0.72        60\n",
      "weighted avg       0.76      0.75      0.74        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('heart_failure_clinical_records_dataset.csv')  # Update with your dataset\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Standardize dataset\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Genetic Algorithm Parameters\n",
    "POPULATION_SIZE = 20\n",
    "GENERATIONS = 10\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "def evaluate_model(individual):\n",
    "    \"\"\"Evaluate a model based on an individual's parameters.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(individual[0], input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(individual[1]),\n",
    "        Dense(individual[2], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(individual[3]),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=individual[4]), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=individual[5], verbose=0, validation_split=0.2)\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def initialize_population():\n",
    "    \"\"\"Initialize the population with random individuals.\"\"\"\n",
    "    population = [\n",
    "        [random.randint(10, 100),  # First layer neurons\n",
    "         random.uniform(0.1, 0.5),  # First layer dropout\n",
    "         random.randint(10, 100),  # Second layer neurons\n",
    "         random.uniform(0.1, 0.5),  # Second layer dropout\n",
    "         random.uniform(0.0001, 0.01),  # Learning rate\n",
    "         random.randint(16, 128)]  # Batch size\n",
    "        for _ in range(POPULATION_SIZE)\n",
    "    ]\n",
    "    return population\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    \"\"\"Perform crossover between two parents.\"\"\"\n",
    "    point = random.randint(1, len(parent1) - 2)  # Random crossover point\n",
    "    child1 = parent1[:point] + parent2[point:]\n",
    "    child2 = parent2[:point] + parent1[point:]\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(individual):\n",
    "    \"\"\"Perform mutation on an individual.\"\"\"\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        index = random.randint(0, len(individual) - 1)\n",
    "        if index in [0, 2, 5]:  # Integer values\n",
    "            individual[index] = random.randint(10, 100 if index != 5 else 128)\n",
    "        elif index in [1, 3]:  # Float values for dropout\n",
    "            individual[index] = random.uniform(0.1, 0.5)\n",
    "        elif index == 4:  # Float values for learning rate\n",
    "            individual[index] = random.uniform(0.0001, 0.01)\n",
    "    return individual\n",
    "\n",
    "# Initialize population\n",
    "population = initialize_population()\n",
    "best_individual = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for generation in range(GENERATIONS):\n",
    "    # Evaluate fitness\n",
    "    fitness_scores = [evaluate_model(individual) for individual in population]\n",
    "    \n",
    "    # Update the best individual\n",
    "    for i, score in enumerate(fitness_scores):\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_individual = population[i]\n",
    "    \n",
    "    # Select parents based on fitness (tournament selection)\n",
    "    selected_parents = []\n",
    "    for _ in range(POPULATION_SIZE // 2):\n",
    "        parent1, parent2 = random.choices(population, weights=fitness_scores, k=2)\n",
    "        selected_parents.append((parent1, parent2))\n",
    "    \n",
    "    # Generate next population through crossover and mutation\n",
    "    next_population = []\n",
    "    for parent1, parent2 in selected_parents:\n",
    "        child1, child2 = crossover(parent1, parent2)\n",
    "        next_population.extend([mutate(child1), mutate(child2)])\n",
    "    \n",
    "    population = next_population[:POPULATION_SIZE]  # Ensure population size remains constant\n",
    "    print(f\"Generation {generation + 1}, Best Accuracy: {best_score}\")\n",
    "\n",
    "# Best solution found\n",
    "print(\"Best Individual:\", best_individual)\n",
    "\n",
    "# Train the best model\n",
    "heart_stroke_model = Sequential([\n",
    "    Dense(best_individual[0], input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(best_individual[1]),\n",
    "    Dense(best_individual[2], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(best_individual[3]),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "heart_stroke_model.compile(optimizer=Adam(learning_rate=best_individual[4]), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "heart_stroke_model.fit(X_train, y_train, epochs=20, batch_size=best_individual[5], verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "heart_stroke_model.save(\"heart_stroke_model.h5\")\n",
    "print(\"Heart Stroke Model Saved!\")\n",
    "\n",
    "# Extract features for Random Forest\n",
    "train_features = heart_stroke_model.predict(X_train)\n",
    "test_features = heart_stroke_model.predict(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(train_features, y_train)\n",
    "\n",
    "# Save Random Forest Model\n",
    "joblib.dump(rf_model, \"random_forest_model.pkl\")\n",
    "print(\"Random Forest Model Saved!\")\n",
    "\n",
    "# Predictions and classification report\n",
    "rf_predictions = rf_model.predict(test_features)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377aa7b9-7d7a-4212-ab4b-596cb4cb5eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
